{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData = pd.read_csv(\"C:/Users/user/Desktop/Fake-News-Detection-using-Twitter-master/FinalDataSet.csv\" , encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_url</th>\n",
       "      <th>statuses/followers_count</th>\n",
       "      <th>friends/followers_count</th>\n",
       "      <th>user_has_url?</th>\n",
       "      <th>Final Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>...</td>\n",
       "      <td>299</td>\n",
       "      <td>410</td>\n",
       "      <td>made in japan</td>\n",
       "      <td>3585</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.37</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>13095</td>\n",
       "      <td>768</td>\n",
       "      <td>Wausau, Wisconsin</td>\n",
       "      <td>53691</td>\n",
       "      <td>True</td>\n",
       "      <td>http://t.co/Ooqm8p3JBi</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>4261</td>\n",
       "      <td>3956</td>\n",
       "      <td>Houston, Texas, U.S.A.</td>\n",
       "      <td>48019</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/xZ5kENca0d</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5649</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/tJVLcw98YK</td>\n",
       "      <td>25.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>1146</td>\n",
       "      <td>5000</td>\n",
       "      <td>Texas</td>\n",
       "      <td>69033</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unique ID                                               text  \\\n",
       "0           0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1           1          2  Students from Riverview Elementary set a goal ...   \n",
       "2           2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3           3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4           4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name  ... user_followers_count  \\\n",
       "0      90  8.800000e+17   itsabinakelley  ...                  299   \n",
       "1     132  1.881336e+07             WAOW  ...                13095   \n",
       "2     112  2.722783e+08    HOUmanitarian  ...                 4261   \n",
       "3      89  3.360066e+07          gdubb79  ...                  220   \n",
       "4      97  1.844070e+07     TexasAmerica  ...                 1146   \n",
       "\n",
       "  user_friends_count           user_location  user_statuses_count  \\\n",
       "0                410           made in japan                 3585   \n",
       "1                768       Wausau, Wisconsin                53691   \n",
       "2               3956  Houston, Texas, U.S.A.                48019   \n",
       "3                683                     NaN                 5649   \n",
       "4               5000                   Texas                69033   \n",
       "\n",
       "   user_verified                 user_url  statuses/followers_count  \\\n",
       "0          False                      NaN                     11.99   \n",
       "1           True   http://t.co/Ooqm8p3JBi                      4.10   \n",
       "2          False  https://t.co/xZ5kENca0d                     11.27   \n",
       "3          False  https://t.co/tJVLcw98YK                     25.68   \n",
       "4          False                      NaN                     60.24   \n",
       "\n",
       "   friends/followers_count user_has_url?  Final Label  \n",
       "0                     1.37            No         REAL  \n",
       "1                     0.06           Yes         REAL  \n",
       "2                     0.93           Yes         REAL  \n",
       "3                     3.10           Yes         REAL  \n",
       "4                     4.36            No         REAL  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import chart_studio\n",
    "from plotly import graph_objs\n",
    "chart_studio.tools.set_credentials_file(username='swmathias', api_key='IUApAvbxLdKWUicRaovv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plotly.com/~swmathias/116.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c3681f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = len(tweetsData[tweetsData[\"Final Label\"] == \"FAKE\"])\n",
    "real = len(tweetsData[tweetsData[\"Final Label\"] == \"REAL\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"fake\",\"real\"],\n",
    "        y=[fake, real],\n",
    ")]\n",
    "py.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Fake and Real Tweets distribution in training set\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    "\n",
    "def preproces(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData['tokenized_text']= tweetsData['text'].apply(preproces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweetsData['token_texts'] = tweetsData['tokenized_text'].apply(lambda x : [w for w in x if w.lower() not in stop_words])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_url</th>\n",
       "      <th>statuses/followers_count</th>\n",
       "      <th>friends/followers_count</th>\n",
       "      <th>user_has_url?</th>\n",
       "      <th>Final Label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>token_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>...</td>\n",
       "      <td>made in japan</td>\n",
       "      <td>3585</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.37</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, to, the, S...</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, Superbowl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>Wausau, Wisconsin</td>\n",
       "      <td>53691</td>\n",
       "      <td>True</td>\n",
       "      <td>http://t.co/Ooqm8p3JBi</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Students, from, Riverview, Elementary, set, a...</td>\n",
       "      <td>[Students, Riverview, Elementary, set, goal, $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>Houston, Texas, U.S.A.</td>\n",
       "      <td>48019</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/xZ5kENca0d</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Harvey, caused, more, than, $, 74, M, in, dam...</td>\n",
       "      <td>[Harvey, caused, $, 74, damage, flood, control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5649</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/tJVLcw98YK</td>\n",
       "      <td>25.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[I, added, a, video, to, a, @YouTube, playlist...</td>\n",
       "      <td>[added, video, @YouTube, playlist, https://t.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>69033</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[DFW, businesses, accused, of, price, gouging,...</td>\n",
       "      <td>[DFW, businesses, accused, price, gouging, Hur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unique ID                                               text  \\\n",
       "0           0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1           1          2  Students from Riverview Elementary set a goal ...   \n",
       "2           2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3           3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4           4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name  ...           user_location  \\\n",
       "0      90  8.800000e+17   itsabinakelley  ...           made in japan   \n",
       "1     132  1.881336e+07             WAOW  ...       Wausau, Wisconsin   \n",
       "2     112  2.722783e+08    HOUmanitarian  ...  Houston, Texas, U.S.A.   \n",
       "3      89  3.360066e+07          gdubb79  ...                     NaN   \n",
       "4      97  1.844070e+07     TexasAmerica  ...                   Texas   \n",
       "\n",
       "  user_statuses_count user_verified                 user_url  \\\n",
       "0                3585         False                      NaN   \n",
       "1               53691          True   http://t.co/Ooqm8p3JBi   \n",
       "2               48019         False  https://t.co/xZ5kENca0d   \n",
       "3                5649         False  https://t.co/tJVLcw98YK   \n",
       "4               69033         False                      NaN   \n",
       "\n",
       "   statuses/followers_count friends/followers_count  user_has_url?  \\\n",
       "0                     11.99                    1.37             No   \n",
       "1                      4.10                    0.06            Yes   \n",
       "2                     11.27                    0.93            Yes   \n",
       "3                     25.68                    3.10            Yes   \n",
       "4                     60.24                    4.36             No   \n",
       "\n",
       "   Final Label                                     tokenized_text  \\\n",
       "0         REAL  [Hurricane, Katrina, -, Saints, go, to, the, S...   \n",
       "1         REAL  [Students, from, Riverview, Elementary, set, a...   \n",
       "2         REAL  [Harvey, caused, more, than, $, 74, M, in, dam...   \n",
       "3         REAL  [I, added, a, video, to, a, @YouTube, playlist...   \n",
       "4         REAL  [DFW, businesses, accused, of, price, gouging,...   \n",
       "\n",
       "                                         token_texts  \n",
       "0  [Hurricane, Katrina, -, Saints, go, Superbowl,...  \n",
       "1  [Students, Riverview, Elementary, set, goal, $...  \n",
       "2  [Harvey, caused, $, 74, damage, flood, control...  \n",
       "3  [added, video, @YouTube, playlist, https://t.c...  \n",
       "4  [DFW, businesses, accused, price, gouging, Hur...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " #function defined to calculate number of occurences of a symbol\n",
    "def count_occurences(character, word_array):\n",
    "    counter = 0\n",
    "    for j, word in enumerate(word_array):\n",
    "        for char in word:\n",
    "            if char == character:\n",
    "                counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates number of ?, !, hashtags and mentions\n",
    "tweetsData['no_of_question_marks'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"?\", txt)) \n",
    "tweetsData['no_of_exclamation_marks'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"!\", txt)) \n",
    "tweetsData['no_of_hashtags'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"#\", txt)) \n",
    "tweetsData['no_of_mentions'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"@\", txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_by_regex(regex,plain_text):\n",
    "    return len(re.findall(regex,plain_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>statuses/followers_count</th>\n",
       "      <th>friends/followers_count</th>\n",
       "      <th>user_has_url?</th>\n",
       "      <th>Final Label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>token_texts</th>\n",
       "      <th>no_of_question_marks</th>\n",
       "      <th>no_of_exclamation_marks</th>\n",
       "      <th>no_of_hashtags</th>\n",
       "      <th>no_of_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>...</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.37</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, to, the, S...</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, Superbowl,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Students, from, Riverview, Elementary, set, a...</td>\n",
       "      <td>[Students, Riverview, Elementary, set, goal, $...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Harvey, caused, more, than, $, 74, M, in, dam...</td>\n",
       "      <td>[Harvey, caused, $, 74, damage, flood, control...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>...</td>\n",
       "      <td>25.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[I, added, a, video, to, a, @YouTube, playlist...</td>\n",
       "      <td>[added, video, @YouTube, playlist, https://t.c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>60.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[DFW, businesses, accused, of, price, gouging,...</td>\n",
       "      <td>[DFW, businesses, accused, price, gouging, Hur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unique ID                                               text  \\\n",
       "0           0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1           1          2  Students from Riverview Elementary set a goal ...   \n",
       "2           2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3           3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4           4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name  ... statuses/followers_count  \\\n",
       "0      90  8.800000e+17   itsabinakelley  ...                    11.99   \n",
       "1     132  1.881336e+07             WAOW  ...                     4.10   \n",
       "2     112  2.722783e+08    HOUmanitarian  ...                    11.27   \n",
       "3      89  3.360066e+07          gdubb79  ...                    25.68   \n",
       "4      97  1.844070e+07     TexasAmerica  ...                    60.24   \n",
       "\n",
       "  friends/followers_count user_has_url?  Final Label  \\\n",
       "0                    1.37            No         REAL   \n",
       "1                    0.06           Yes         REAL   \n",
       "2                    0.93           Yes         REAL   \n",
       "3                    3.10           Yes         REAL   \n",
       "4                    4.36            No         REAL   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Hurricane, Katrina, -, Saints, go, to, the, S...   \n",
       "1  [Students, from, Riverview, Elementary, set, a...   \n",
       "2  [Harvey, caused, more, than, $, 74, M, in, dam...   \n",
       "3  [I, added, a, video, to, a, @YouTube, playlist...   \n",
       "4  [DFW, businesses, accused, of, price, gouging,...   \n",
       "\n",
       "                                         token_texts  no_of_question_marks  \\\n",
       "0  [Hurricane, Katrina, -, Saints, go, Superbowl,...                     0   \n",
       "1  [Students, Riverview, Elementary, set, goal, $...                     0   \n",
       "2  [Harvey, caused, $, 74, damage, flood, control...                     0   \n",
       "3  [added, video, @YouTube, playlist, https://t.c...                     0   \n",
       "4  [DFW, businesses, accused, price, gouging, Hur...                     0   \n",
       "\n",
       "   no_of_exclamation_marks no_of_hashtags  no_of_mentions  \n",
       "0                        0              0               0  \n",
       "1                        0              0               0  \n",
       "2                        0              0               1  \n",
       "3                        0              0               1  \n",
       "4                        0              0               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates number of URLs in a tweet\n",
    "tweetsData['no_of_urls'] = tweetsData['text'].apply(lambda txt:count_by_regex(\"http.?://[^\\s]+[\\s]?\",txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not working as of now. Need to look at it later if needed\n",
    "class EmoticonDetector:\n",
    "    emoticons = {}\n",
    "\n",
    "    def __init__(self, emoticon_file=\"C://SHERYL MATHIAS/US Aug 2016/Fall 2017/INFM750/emoticons.txt\"):\n",
    "        from pathlib import Path\n",
    "        content = Path(emoticon_file).read_text()\n",
    "        positive = True\n",
    "        for line in content.split(\"\\n\"):\n",
    "            if \"positive\" in line.lower():\n",
    "                positive = True\n",
    "                continue\n",
    "            elif \"negative\" in line.lower():\n",
    "                positive = False\n",
    "                continue\n",
    "\n",
    "            self.emoticons[line] = positive\n",
    "\n",
    "    def is_positive(self, emoticon):\n",
    "        if emoticon in self.emoticons:\n",
    "            return self.emoticons[emoticon]\n",
    "        return False\n",
    "\n",
    "    def is_emoticon(self, to_check):\n",
    "        return to_check in self.emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_by_lambda(expression, word_array):\n",
    "    return len(list(filter(expression, word_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May need this code later. But this code does not work\n",
    "#ed = EmoticonDetector()\n",
    "#tweetsData['no_of_positive_emoticons'] = tweetsData['text'].apply(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData.to_csv(\"C:/Users/user/Desktop/Fake-News-Detection-using-Twitter-master/FinalDS_AdditionalFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweetsData['no_of_uppercase_words'] = tweetsData['tokenized_text'].apply(lambda txt: count_by_lambda(lambda word: word == word.upper(), \n",
    "#                                                                                          txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Remove URLs and mentions from tweets\n",
    "def remove_url_by_regex(pattern,string):\n",
    "    return re.sub(pattern,\"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes URLs\n",
    "tweetsData['cleaned_text'] = tweetsData['text'].apply(lambda txt:remove_url_by_regex(\"http.?://[^\\s]+[\\s]?\",txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes mentions\n",
    "tweetsData['cleaned_text'] = tweetsData['cleaned_text'].apply(lambda txt:remove_url_by_regex(r'(?:@[\\w_]+)',txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strs = \"how much for the maple syrup??? $20.99? That's?ricidulous!!!\"\n",
    "# print(strs)\n",
    "# nstr = re.sub(r'[?|$|.|!]',r'',strs)\n",
    "# print (nstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates number of colon marks\n",
    "tweetsData['no_of_colon_marks'] = tweetsData['cleaned_text'].apply(lambda txt: count_occurences(\":\", txt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation marks\n",
    "tweetsData['cleaned_text'] = tweetsData['cleaned_text'].apply(lambda txt:remove_url_by_regex(r'[,|:|\\|=|&|;|%|$|@|^|*|-|#|?|!|.]',txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts number of words\n",
    "tweetsData['no_of_words'] = tweetsData['cleaned_text'].apply(lambda txt:len(re.findall(r'\\w+',txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
